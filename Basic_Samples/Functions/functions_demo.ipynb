{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with functions in Azure OpenAI\n",
    "This notebook shows how to use the Chat Completions API in combination with functions to extend the current capabilities of GPT models. GPT models, do not inherently support real-time interaction with external systems, databases, or files. However, functions can be used to do so.\n",
    "\n",
    "Overview: <br>\n",
    "`functions` is an optional parameter in the Chat Completion API which can be used to provide function specifications. This allows models to generate function arguments for the specifications provided by the user. \n",
    "\n",
    "Note: The API will not execute any function calls. Executing function calls using the outputed argments must be done by developers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\t-amfoster\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n",
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Load config values\n",
    "with open(r'config.json') as config_file:\n",
    "    config_details = json.load(config_file)\n",
    "    \n",
    "# Setting up the deployment name\n",
    "deployment_id = config_details['DEPLOYMENT_ID']\n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = config_details['OPENAI_API_BASE']\n",
    "\n",
    "# Currently Chat Completion API have the following versions available: 2023-07-01-preview\n",
    "openai.api_version = config_details['OPENAI_API_VERSION']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Test functions\n",
    "\n",
    "This code calls the model with the user query and the set of functions defined in the functions parameter. The model then can choose if it calls a function. If a function is called, the content will be in a strigified JSON object. The function call that should be made and arguments are location in:  response[`choices`][0][`function_call`]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_call(messages, function_call = \"auto\"):\n",
    "    # Define the functions to use\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Call the model with the user query (messages) and the functions defined in the functions parameter\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id = deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=function_call, \n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcing the use of a specific function or no function\n",
    "By changing the value of the `functions` parameter you can allow the model to decide what function to use, force the model to use a specific function, or force the model to use no function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let the model decide what function to call:\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m# 'auto' : Let the model decide what function to call\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLet the model decide what function to call:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m (get_function_call(first_message, \u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      7\u001b[0m \u001b[39m# 'none' : Don't call any function \u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDon\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt call any function:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m, in \u001b[0;36mget_function_call\u001b[1;34m(messages, function_call)\u001b[0m\n\u001b[0;32m      3\u001b[0m functions \u001b[39m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     {\n\u001b[0;32m      5\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mget_current_weather\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     },\n\u001b[0;32m     19\u001b[0m ]\n\u001b[0;32m     21\u001b[0m \u001b[39m# Call the model with the user query (messages) and the functions defined in the functions parameter\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     23\u001b[0m     deployment_id \u001b[39m=\u001b[39;49m deployment_id,\n\u001b[0;32m     24\u001b[0m     messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     25\u001b[0m     functions\u001b[39m=\u001b[39;49mfunctions,\n\u001b[0;32m     26\u001b[0m     function_call\u001b[39m=\u001b[39;49mfunction_call, \n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:149\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[0;32m    141\u001b[0m         timeout,\n\u001b[0;32m    142\u001b[0m         stream,\n\u001b[0;32m    143\u001b[0m         headers,\n\u001b[0;32m    144\u001b[0m         request_timeout,\n\u001b[0;32m    145\u001b[0m         typed_api_type,\n\u001b[0;32m    146\u001b[0m         requestor,\n\u001b[0;32m    147\u001b[0m         url,\n\u001b[0;32m    148\u001b[0m         params,\n\u001b[1;32m--> 149\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__prepare_create_request(\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[0;32m    153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:106\u001b[0m, in \u001b[0;36mEngineAPIResource.__prepare_create_request\u001b[1;34m(cls, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     params[\u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m MAX_TIMEOUT\n\u001b[1;32m--> 106\u001b[0m requestor \u001b[39m=\u001b[39m api_requestor\u001b[39m.\u001b[39;49mAPIRequestor(\n\u001b[0;32m    107\u001b[0m     api_key,\n\u001b[0;32m    108\u001b[0m     api_base\u001b[39m=\u001b[39;49mapi_base,\n\u001b[0;32m    109\u001b[0m     api_type\u001b[39m=\u001b[39;49mapi_type,\n\u001b[0;32m    110\u001b[0m     api_version\u001b[39m=\u001b[39;49mapi_version,\n\u001b[0;32m    111\u001b[0m     organization\u001b[39m=\u001b[39;49morganization,\n\u001b[0;32m    112\u001b[0m )\n\u001b[0;32m    113\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[0;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    115\u001b[0m     deployment_id,\n\u001b[0;32m    116\u001b[0m     engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    124\u001b[0m     params,\n\u001b[0;32m    125\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\api_requestor.py:138\u001b[0m, in \u001b[0;36mAPIRequestor.__init__\u001b[1;34m(self, key, api_base, api_type, api_version, organization)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    130\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    131\u001b[0m     key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m     organization\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    136\u001b[0m ):\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_base \u001b[39m=\u001b[39m api_base \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_base\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key \u001b[39mor\u001b[39;00m util\u001b[39m.\u001b[39;49mdefault_api_key()\n\u001b[0;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_type \u001b[39m=\u001b[39m (\n\u001b[0;32m    140\u001b[0m         ApiType\u001b[39m.\u001b[39mfrom_str(api_type)\n\u001b[0;32m    141\u001b[0m         \u001b[39mif\u001b[39;00m api_type\n\u001b[0;32m    142\u001b[0m         \u001b[39melse\u001b[39;00m ApiType\u001b[39m.\u001b[39mfrom_str(openai\u001b[39m.\u001b[39mapi_type)\n\u001b[0;32m    143\u001b[0m     )\n\u001b[0;32m    144\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_version \u001b[39m=\u001b[39m api_version \u001b[39mor\u001b[39;00m openai\u001b[39m.\u001b[39mapi_version\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\util.py:186\u001b[0m, in \u001b[0;36mdefault_api_key\u001b[1;34m()\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39mapi_key\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[39mraise\u001b[39;00m openai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[0;32m    187\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo API key provided. You can set your API key in code using \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key = <API-KEY>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001b[39m\u001b[39m'\u001b[39m\u001b[39mopenai.api_key_path = <PATH>\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m     )\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details."
     ]
    }
   ],
   "source": [
    "first_message = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
    "# 'auto' : Let the model decide what function to call\n",
    "print(\"Let the model decide what function to call:\")\n",
    "print (get_function_call(first_message, \"auto\"))\n",
    "\n",
    "\n",
    "# 'none' : Don't call any function \n",
    "print(\"Don't call any function:\")\n",
    "print (get_function_call(first_message, \"none\"))\n",
    "\n",
    "# force a specific function call\n",
    "print(\"Force a specific function call:\")\n",
    "print (get_function_call(first_message, function_call={\"name\": \"get_current_weather\"}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Defining functions\n",
    "Now that we know how to work with functions, let's define some functions in code so that we can walk through the process of using functions end to end."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #1: Get current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_time(location):\n",
    "    try:\n",
    "        # Get the timezone for the city\n",
    "        timezone = pytz.timezone(location)\n",
    "\n",
    "        # Get the current time in the timezone\n",
    "        now = datetime.now(timezone)\n",
    "        current_time = now.strftime(\"%I:%M:%S %p\")\n",
    "\n",
    "        return current_time\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find the timezone for that location.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03:21:55 PM'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time(\"America/New_York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #2: Get stock market data\n",
    "For simplicity, we're just hard coding some stock market data but you could easily edit the code to call out to an API to retrieve real-time data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define your data\n",
    "data = [\n",
    "    {'Index': 'S&P 500', 'Date': '2023-07-12', 'Open': 4300.25, 'High': 4350.32, 'Low': 4200.20, 'Close': 4325.74, 'Volume': 3500000},\n",
    "    {'Index': 'S&P 500', 'Date': '2023-07-13', 'Open': 4325.55, 'High': 4350.00, 'Low': 4300.98, 'Close': 4310.33, 'Volume': 3600000},\n",
    "    {'Index': 'NASDAQ Composite', 'Date': '2023-07-12', 'Open': 14000.65, 'High': 14200.06, 'Low': 13800.08, 'Close': 14100.44, 'Volume': 4000000},\n",
    "    {'Index': 'NASDAQ Composite', 'Date': '2023-07-13', 'Open': 14100.11, 'High': 14250.00, 'Low': 14000.67, 'Close': 14050.81, 'Volume': 4200000},\n",
    "    {'Index': 'Dow Jones Industrial Average', 'Date': '2023-07-12', 'Open': 34000.87, 'High': 34500.22, 'Low': 33000.11, 'Close': 34200.90, 'Volume': 3000000},\n",
    "    {'Index': 'Dow Jones Industrial Average', 'Date': '2023-07-13', 'Open': 34200.73, 'High': 34500.73, 'Low': 34000.40, 'Close': 34100.64, 'Volume': 3200000},\n",
    "    {'Index': 'Financial Times Stock Exchange 100 Index', 'Date': '2023-07-12', 'Open': 7000.55, 'High': 7050.61, 'Low': 6900.76, 'Close': 7025.22, 'Volume': 2000000},\n",
    "    {'Index': 'Financial Times Stock Exchange 100 Index', 'Date': '2023-07-13', 'Open': 7025.39, 'High': 7050.90, 'Low': 7000.56, 'Close': 7010.24, 'Volume': 2100000}\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('stock_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_stock_market_data(index):\n",
    "    available_indices = [\"S&P 500\", \"NASDAQ Composite\", \"Dow Jones Industrial Average\", \"Financial Times Stock Exchange 100 Index\"]\n",
    "\n",
    "    if index not in available_indices:\n",
    "        return \"Invalid index. Please choose from 'S&P 500', 'NASDAQ Composite', 'Dow Jones Industrial Average', 'Financial Times Stock Exchange 100 Index'.\"\n",
    "\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv('stock_data.csv')\n",
    "\n",
    "    # Filter data for the given index\n",
    "    data_filtered = data[data['Index'] == index]\n",
    "\n",
    "    # Remove 'Index' column\n",
    "    data_filtered = data_filtered.drop(columns=['Index'])\n",
    "\n",
    "    # Convert the DataFrame into a dictionary\n",
    "    hist_dict = data_filtered.to_dict()\n",
    "\n",
    "    for key, value_dict in hist_dict.items():\n",
    "        hist_dict[key] = {k: v for k, v in value_dict.items()}\n",
    "\n",
    "    return json.dumps(hist_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Date\": {\"2\": \"2023-07-12\", \"3\": \"2023-07-13\"}, \"Open\": {\"2\": 14000.65, \"3\": 14100.11}, \"High\": {\"2\": 14200.06, \"3\": 14250.0}, \"Low\": {\"2\": 13800.08, \"3\": 14000.67}, \"Close\": {\"2\": 14100.44, \"3\": 14050.81}, \"Volume\": {\"2\": 4000000, \"3\": 4200000}}\n"
     ]
    }
   ],
   "source": [
    "print(get_stock_market_data(\"NASDAQ Composite\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #3: Calculator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculator(num1, num2, operator):\n",
    "    if operator == '+':\n",
    "        return str(num1 + num2)\n",
    "    elif operator == '-':\n",
    "        return str(num1 - num2)\n",
    "    elif operator == '*':\n",
    "        return str(num1 * num2)\n",
    "    elif operator == '/':\n",
    "        return str(num1 / num2)\n",
    "    elif operator == '**':\n",
    "        return str(num1 ** num2)\n",
    "    elif operator == 'sqrt':\n",
    "        return str(math.sqrt(num1))\n",
    "    else:\n",
    "        return \"Invalid operator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(calculator(5, 5, '+'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Calling a Function using GPT\n",
    "\n",
    "Steps for Function Calling: \n",
    "\n",
    "1. Call the model with the user query and a set of functions defined in the functions parameter.\n",
    "2. The model can choose to call a function; if so, the content will be a stringified JSON object adhering to your custom schema (note: the model may generate invalid JSON or hallucinate parameters).\n",
    "3. Parse the string into JSON in your code, and call your function with the provided arguments if they exist.\n",
    "4. Call the model again by appending the function response as a new message, and let the model summarize the results back to the user.\n",
    "\n",
    "### 3.1 Describe the functions so that the model knows how to call them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"Get the current time in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location name. The pytz is used to get the timezone for that location. Location names should be in a format like America/New_York, Asia/Bangkok, Europe/London\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_stock_market_data\",\n",
    "            \"description\": \"Get the stock market data for a given index\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"index\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"S&P 500\", \"NASDAQ Composite\", \"Dow Jones Industrial Average\", \"Financial Times Stock Exchange 100 Index\"]},\n",
    "                },\n",
    "                \"required\": [\"index\"],\n",
    "            },    \n",
    "        },\n",
    "        {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"A simple calculator used to perform basic arithmetic operations\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"},\n",
    "                    \"operator\": {\"type\": \"string\", \"enum\": [\"+\", \"-\", \"*\", \"/\", \"**\", \"sqrt\"]},\n",
    "                },\n",
    "                \"required\": [\"num1\", \"num2\", \"operator\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "available_functions = {\n",
    "            \"get_current_time\": get_current_time,\n",
    "            \"get_stock_market_data\": get_stock_market_data,\n",
    "            \"calculator\": calculator,\n",
    "        } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define a helper function to validate the function call\n",
    "It's possible that the models could generate incorrect function calls so it's important to validate the calls. Here we define a simple helper function to validate the function call although you could apply more complex validation for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# helper method used to check if the correct arguments are provided to a function\n",
    "def check_args(function, args):\n",
    "    sig = inspect.signature(function)\n",
    "    params = sig.parameters\n",
    "\n",
    "    # Check if there are extra arguments\n",
    "    for name in args:\n",
    "        if name not in params:\n",
    "            return False\n",
    "    # Check if the required arguments are provided \n",
    "    for name, param in params.items():\n",
    "        if param.default is param.empty and name not in args:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, functions, available_functions, deployment_id):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        \n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        fuction_to_call = available_functions[function_name]  \n",
    "        \n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if check_args(fuction_to_call, function_args) is False:\n",
    "            return \"Invalid number of arguments for function: \" + function_name\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in second request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"get_current_time\",\n",
      "  \"arguments\": \"{\\n  \\\"location\\\": \\\"America/New_York\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "03:22:04 PM\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'user', 'content': 'What time is it in New York?'}\n",
      "{'role': 'assistant', 'name': 'get_current_time', 'content': '{\\n  \"location\": \"America/New_York\"\\n}'}\n",
      "{'role': 'function', 'name': 'get_current_time', 'content': '03:22:04 PM'}\n",
      "\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The current time in New York is 03:22 PM.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What time is it in New York?\"}]\n",
    "assistant_response = run_conversation(messages, functions, available_functions, deployment_id)\n",
    "print(assistant_response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Calling multiple functions together\n",
    "In some cases, you may want to string together multiple function calls to get the desired result. We modified the `run_conversation()` function above to allow multiple function calls to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiturn_conversation(messages, functions, available_functions, deployment_id):\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    while response[\"choices\"][0][\"finish_reason\"] == 'function_call':\n",
    "        response_message = response[\"choices\"][0][\"message\"]\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        \n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        fuction_to_call = available_functions[function_name]  \n",
    "        \n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        if check_args(fuction_to_call, function_args) is False:\n",
    "            return \"Invalid number of arguments for function: \" + function_name\n",
    "        function_response = fuction_to_call(**function_args)\n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in next request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id,\n",
    "            function_call=\"auto\",\n",
    "            functions=functions,\n",
    "            temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"get_stock_market_data\",\n",
      "  \"arguments\": \"{\\n  \\\"index\\\": \\\"S&P 500\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "{\"Date\": {\"0\": \"2023-07-12\", \"1\": \"2023-07-13\"}, \"Open\": {\"0\": 4300.25, \"1\": 4325.55}, \"High\": {\"0\": 4350.32, \"1\": 4350.0}, \"Low\": {\"0\": 4200.2, \"1\": 4300.98}, \"Close\": {\"0\": 4325.74, \"1\": 4310.33}, \"Volume\": {\"0\": 3500000, \"1\": 3600000}}\n",
      "\n",
      "Messages in next request:\n",
      "{'role': 'system', 'content': 'Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.'}\n",
      "{'role': 'user', 'content': 'How much did S&P 500 change between July 12 and July 13? Use the calculator.'}\n",
      "{'role': 'assistant', 'name': 'get_stock_market_data', 'content': '{\\n  \"index\": \"S&P 500\"\\n}'}\n",
      "{'role': 'function', 'name': 'get_stock_market_data', 'content': '{\"Date\": {\"0\": \"2023-07-12\", \"1\": \"2023-07-13\"}, \"Open\": {\"0\": 4300.25, \"1\": 4325.55}, \"High\": {\"0\": 4350.32, \"1\": 4350.0}, \"Low\": {\"0\": 4200.2, \"1\": 4300.98}, \"Close\": {\"0\": 4325.74, \"1\": 4310.33}, \"Volume\": {\"0\": 3500000, \"1\": 3600000}}'}\n",
      "\n",
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"calculator\",\n",
      "  \"arguments\": \"{\\n  \\\"num1\\\": 4310.33,\\n  \\\"num2\\\": 4325.74,\\n  \\\"operator\\\": \\\"-\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "-15.409999999999854\n",
      "\n",
      "Messages in next request:\n",
      "{'role': 'system', 'content': 'Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.'}\n",
      "{'role': 'user', 'content': 'How much did S&P 500 change between July 12 and July 13? Use the calculator.'}\n",
      "{'role': 'assistant', 'name': 'get_stock_market_data', 'content': '{\\n  \"index\": \"S&P 500\"\\n}'}\n",
      "{'role': 'function', 'name': 'get_stock_market_data', 'content': '{\"Date\": {\"0\": \"2023-07-12\", \"1\": \"2023-07-13\"}, \"Open\": {\"0\": 4300.25, \"1\": 4325.55}, \"High\": {\"0\": 4350.32, \"1\": 4350.0}, \"Low\": {\"0\": 4200.2, \"1\": 4300.98}, \"Close\": {\"0\": 4325.74, \"1\": 4310.33}, \"Volume\": {\"0\": 3500000, \"1\": 3600000}}'}\n",
      "{'role': 'assistant', 'name': 'calculator', 'content': '{\\n  \"num1\": 4310.33,\\n  \"num2\": 4325.74,\\n  \"operator\": \"-\"\\n}'}\n",
      "{'role': 'function', 'name': 'calculator', 'content': '-15.409999999999854'}\n",
      "\n",
      "Final Response:\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The S&P 500 index changed by approximately -15.41 points between July 12 and July 13.\"\n",
      "}\n",
      "Conversation complete!\n"
     ]
    }
   ],
   "source": [
    "# Can add system prompting to guide the model to call functions and perform in specific ways\n",
    "next_messages = [{\"role\": \"system\", \"content\": \"Assistant is a helpful assistant that helps users get answers to questions. Assistant has access to several tools and sometimes you may need to call multiple tools in sequence to get answers for your users.\"}]\n",
    "next_messages.append({\"role\": \"user\", \"content\": \"How much did S&P 500 change between July 12 and July 13? Use the calculator.\"})\n",
    "\n",
    "assistant_response = run_multiturn_conversation(next_messages, functions, available_functions, deployment_id)\n",
    "print(\"Final Response:\")\n",
    "print(assistant_response[\"choices\"][0][\"message\"])\n",
    "print(\"Conversation complete!\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
